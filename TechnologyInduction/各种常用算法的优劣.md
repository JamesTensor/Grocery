1. 线性回归，Linear regression.

优点：简单，上手快，对线性可分的数据有效，正则和cross-validation 可以避免过拟合。

缺点：对outlier敏感，很容易过拟合或者欠拟合. 无法处理非线性数据。

\2. 逻辑回归， Logistic regression.

优点：简单，上手快，数据做不做预处理都无所谓，输出数据自动落入（0，1）区间，对输入数据的微小波动不敏感，可以通过数值分析方法进行模型优化。

缺点：非线性数据表现不好，对于特征highly correlated的表现不好， 特征必须有明确指向性。

\3. SVM

优点：线性非线性数据都可以处理，高维数据表现不错，当类型明确可分的时候是最优选择，outliers影响很小。

缺点：慢， 当类型互相重叠时候表现不太好，kernel选择很重要，参数选择也很关键。

\4. Neural Network

优点：整体表现良好， 输入数据的波动影响小

缺点：慢，隐藏层选择很重要

\5. Naive Bayes

优点：快，无需训练时间，较少的训练数据表现相对更好。irrelevant features 影响非常小，高维数据表现好。

缺点：不适合做预测， 输入数据必须代表整体分布不然会导致结果不好。

\6. 决策树

优点：不需要预处理数据，可以处理部分数据丢失的情况，可以可视化，容易理解。

缺点：容易过拟合，对outlier非常敏感，输入数据的微小波动会引起输出的大幅变化，不平衡/高维数据训练时间长。

\7. 随机森林

优点：人多力量大，可以降低综合误差（bias & variance），可以处理高维数据，不会出现过拟合。

缺点：具体过程无法可视化，特征选择比较关键。

\8. KNN

优点：简单好上手，对输入数据无要求，参数少，只有一个K

缺点：大量数据处理慢，数据量大+特征多的时候表现不好，imbalanced数据表现不好，无法处理数据丢失。

\9. K-mean

优点：可处理大量数据，保证收敛，对新数据适应良好。

缺点：人工选择K， 初始数据完全影响整个模型的结果，高维数据速度慢，对outliers敏感。



\10. 如何选择ML模型， 著名no free lunch theroem（可不是我瞎说的）已经表示，不可能有一个全方面称心如意的模型可以解决你的所有问题，就像择偶时候，不可能有兼具帅气多金温柔上进体贴智慧专一。。。于一身的人，主要还是看你更需要什么了。

实际选择模型时候可以从以下方面考虑：

10.1 训练数据

数据量是大还是小，数据是high bias 还是 high variance。。。

数据小，或者数据high bias/ low variance 可以选择linear、 logistics regression, Naïve Bayes, 或者SVM无kernel。

数据量大或low bias / high variance 可选择KNN, SVM 高斯kernel, 决策树。

10.2 数据的结构

考虑数据是线性还是非线性，相关还是不相关，根据上面的模型优缺点进行选择

10.3 训练时间

是想一杯茶喝一天等结果还是想嗖的一下就出结果，可以根据模型本身的速度选择。

10.4 数据特征

特征多还是少，特征是有明确指向性还是没有，特征之间有无重叠，都可以根据具体要求选择合适的模型。

